#!/usr/bin/env python3
"""
å‘ç°OI Wikiå®é™…çš„é¡µé¢ç»“æ„
"""

import requests
import urllib3
from bs4 import BeautifulSoup
from urllib.parse import urljoin, urlparse
import time
import json
import re
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

# ç¦ç”¨SSLè­¦å‘Š
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

BASE_URL = "https://oi-wiki.org/"

def setup_driver():
    """è®¾ç½®Chromeæµè§ˆå™¨é©±åŠ¨"""
    chrome_options = Options()
    chrome_options.add_argument('--headless')
    chrome_options.add_argument('--no-sandbox')
    chrome_options.add_argument('--disable-dev-shm-usage')
    chrome_options.add_argument('--disable-gpu')
    chrome_options.add_argument('--window-size=1920,1080')
    chrome_options.add_argument('--disable-web-security')
    chrome_options.add_argument('--ignore-certificate-errors')
    chrome_options.add_argument('--disable-blink-features=AutomationControlled')
    chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
    chrome_options.add_experimental_option('useAutomationExtension', False)
    chrome_options.add_argument('--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36')
    
    try:
        driver = webdriver.Chrome(options=chrome_options)
        driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
        return driver
    except Exception as e:
        print(f"âŒ Chrome driver setup failed: {e}")
        return None

def get_sidebar_links(driver, url):
    """è·å–é¡µé¢ä¾§è¾¹æ çš„æ‰€æœ‰é“¾æ¥"""
    try:
        print(f"æ­£åœ¨è®¿é—®: {url}")
        driver.get(url)
        
        # ç­‰å¾…é¡µé¢åŠ è½½å®Œæˆ
        WebDriverWait(driver, 20).until(
            EC.presence_of_element_located((By.TAG_NAME, "body"))
        )
        
        # é¢å¤–ç­‰å¾…ç¡®ä¿å†…å®¹å®Œå…¨åŠ è½½
        time.sleep(5)
        
        # è·å–é¡µé¢HTML
        html = driver.page_source
        soup = BeautifulSoup(html, 'html.parser')
        
        # æŸ¥æ‰¾ä¾§è¾¹æ å¯¼èˆª
        sidebar_selectors = [
            '.md-nav--secondary',  # MkDocs Materialä¸»é¢˜çš„ä¾§è¾¹æ 
            '.md-nav__list',       # å¯¼èˆªåˆ—è¡¨
            '.toc',                # ç›®å½•
            'nav',                 # é€šç”¨å¯¼èˆª
            '.sidebar',            # é€šç”¨ä¾§è¾¹æ 
            '.navigation'          # å¯¼èˆªåŒºåŸŸ
        ]
        
        all_links = []
        
        for selector in sidebar_selectors:
            sidebar = soup.select(selector)
            if sidebar:
                print(f"æ‰¾åˆ°ä¾§è¾¹æ : {selector}")
                for nav in sidebar:
                    links = nav.find_all('a', href=True)
                    for link in links:
                        href = link['href']
                        text = link.get_text().strip()
                        if href.startswith('/') or href.startswith('http'):
                            all_links.append({
                                'href': href,
                                'text': text,
                                'selector': selector
                            })
        
        # å¦‚æœä¾§è¾¹æ æ–¹æ³•å¤±è´¥ï¼Œå°è¯•è·å–æ‰€æœ‰å†…éƒ¨é“¾æ¥
        if not all_links:
            print("ä¾§è¾¹æ æ–¹æ³•å¤±è´¥ï¼Œå°è¯•è·å–æ‰€æœ‰å†…éƒ¨é“¾æ¥...")
            all_page_links = soup.find_all('a', href=True)
            for link in all_page_links:
                href = link['href']
                text = link.get_text().strip()
                if href.startswith('/') and not href.startswith('//'):
                    all_links.append({
                        'href': href,
                        'text': text,
                        'selector': 'all_links'
                    })
        
        return all_links
        
    except Exception as e:
        print(f"è·å–ä¾§è¾¹æ å¤±è´¥: {e}")
        return []

def discover_topic_pages():
    """å‘ç°ä¸“é¢˜ç®—æ³•é¡µé¢"""
    driver = setup_driver()
    if not driver:
        print("âŒ æ— æ³•è®¾ç½®æµè§ˆå™¨é©±åŠ¨")
        return []
    
    try:
        # å°è¯•è®¿é—®ä¸“é¢˜ç®—æ³•ä¸»é¡µ
        topic_urls = [
            "https://oi-wiki.org/topic/",
            "https://oi-wiki.org/",  # ä¸»é¡µ
        ]
        
        all_topic_links = []
        
        for url in topic_urls:
            print(f"\nğŸ” æ­£åœ¨åˆ†æ: {url}")
            links = get_sidebar_links(driver, url)
            
            # ç­›é€‰topicç›¸å…³çš„é“¾æ¥
            topic_links = []
            for link in links:
                href = link['href']
                if '/topic/' in href:
                    topic_links.append(link)
            
            print(f"æ‰¾åˆ° {len(topic_links)} ä¸ªtopicç›¸å…³é“¾æ¥:")
            for link in topic_links:
                print(f"  {link['href']} -> {link['text']}")
            
            all_topic_links.extend(topic_links)
        
        # å»é‡
        unique_links = {}
        for link in all_topic_links:
            href = link['href'].rstrip('/')
            if href not in unique_links:
                unique_links[href] = link
        
        return list(unique_links.values())
        
    except Exception as e:
        print(f"å‘ç°é¡µé¢å¤±è´¥: {e}")
        return []
    finally:
        driver.quit()

def analyze_all_categories():
    """åˆ†ææ‰€æœ‰åˆ†ç±»çš„é¡µé¢"""
    driver = setup_driver()
    if not driver:
        return {}
    
    try:
        # ä¸»è¦åˆ†ç±»é¡µé¢
        category_urls = {
            'math': 'https://oi-wiki.org/math/',
            'ds': 'https://oi-wiki.org/ds/',
            'graph': 'https://oi-wiki.org/graph/',
            'string': 'https://oi-wiki.org/string/',
            'dp': 'https://oi-wiki.org/dp/',
            'search': 'https://oi-wiki.org/search/',
            'basic': 'https://oi-wiki.org/basic/',
            'misc': 'https://oi-wiki.org/misc/',
            'geometry': 'https://oi-wiki.org/geometry/',
            'topic': 'https://oi-wiki.org/topic/',
        }
        
        all_results = {}
        
        for category, url in category_urls.items():
            print(f"\nğŸ” åˆ†æåˆ†ç±»: {category} - {url}")
            links = get_sidebar_links(driver, url)
            
            # ç­›é€‰è¯¥åˆ†ç±»çš„é“¾æ¥
            category_links = []
            for link in links:
                href = link['href']
                if f'/{category}/' in href:
                    category_links.append(link)
            
            print(f"æ‰¾åˆ° {len(category_links)} ä¸ª {category} ç›¸å…³é“¾æ¥")
            all_results[category] = category_links
            
            # é€‚å½“å»¶æ—¶
            time.sleep(3)
        
        return all_results
        
    except Exception as e:
        print(f"åˆ†æåˆ†ç±»å¤±è´¥: {e}")
        return {}
    finally:
        driver.quit()

if __name__ == "__main__":
    print("ğŸš€ å‘ç°OI Wikiå®é™…é¡µé¢ç»“æ„")
    print("=" * 60)
    
    # é¦–å…ˆä¸“æ³¨äºtopicåˆ†ç±»
    print("\nğŸ“š ä¸“é—¨åˆ†ætopicåˆ†ç±»...")
    topic_links = discover_topic_pages()
    
    print(f"\nâœ… å‘ç° {len(topic_links)} ä¸ªtopicé¡µé¢:")
    topic_mapping = {}
    for link in topic_links:
        href = link['href'].strip('/')
        text = link['text']
        if href.startswith('/'):
            href = href[1:]  # ç§»é™¤å¼€å¤´çš„/
        topic_mapping[href] = text
        print(f"  \"{href}\": \"{text}\",")
    
    # ä¿å­˜ç»“æœ
    with open('discovered_topics.json', 'w', encoding='utf-8') as f:
        json.dump(topic_mapping, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜åˆ° discovered_topics.json")


