#!/usr/bin/env python3
"""
æµ‹è¯•OI Wikiçš„URLç»“æ„ï¼Œç¡®å®šå“ªäº›é¡µé¢å®é™…å­˜åœ¨
"""

import requests
import urllib3
from urllib.parse import urljoin

# ç¦ç”¨SSLè­¦å‘Š
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

BASE_URL = "https://oi-wiki.org/"

# æµ‹è¯•ç”¨æˆ·æåˆ°çš„URL
test_urls = [
    # ç”¨æˆ·è¯´ä¸å­˜åœ¨çš„
    "topic/lca/",
    
    # ç”¨æˆ·è¯´å­˜åœ¨çš„  
    "topic/dsu-app/",
    
    # å…¶ä»–ä¸€äº›å¯èƒ½çš„topic URL
    "topic/rmq/",
    "topic/offline-lca/",
    "topic/tree-centroid/",
    "topic/palindrome/",
    
    # ä¸€äº›å¯èƒ½å­˜åœ¨çš„topic URLï¼ˆæ ¹æ®å¸¸è§ç®—æ³•ä¸»é¢˜æ¨æµ‹ï¼‰
    "topic/dsu/",
    "topic/binary-lifting/",
    "topic/heavy-light/",
    "topic/centroid-decomposition/",
    "topic/mo-algorithm/",
    "topic/sqrt-decomposition/",
]

def test_url(url_path):
    """æµ‹è¯•URLæ˜¯å¦å¯è®¿é—®"""
    full_url = urljoin(BASE_URL, url_path)
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        response = requests.get(full_url, verify=False, headers=headers, timeout=10)
        return response.status_code, response.url
    except Exception as e:
        return f"Error: {e}", full_url

print("ğŸ” æµ‹è¯•OI Wiki URLç»“æ„...")
print("=" * 60)

existing_urls = []
non_existing_urls = []

for url_path in test_urls:
    status, final_url = test_url(url_path)
    print(f"Testing: {url_path:<25} -> Status: {status}")
    
    if isinstance(status, int):
        if status == 200:
            existing_urls.append(url_path)
            print(f"  âœ… å­˜åœ¨: {final_url}")
        elif status == 404:
            non_existing_urls.append(url_path)
            print(f"  âŒ ä¸å­˜åœ¨")
        elif status == 403:
            print(f"  âš ï¸  è®¿é—®è¢«æ‹’ç»")
        else:
            print(f"  â“ çŠ¶æ€ç : {status}")
    else:
        print(f"  âŒ é”™è¯¯: {status}")
    print()

print("\nğŸ“Š æ€»ç»“:")
print(f"âœ… å­˜åœ¨çš„URL ({len(existing_urls)}):")
for url in existing_urls:
    print(f"  - {url}")

print(f"\nâŒ ä¸å­˜åœ¨çš„URL ({len(non_existing_urls)}):")
for url in non_existing_urls:
    print(f"  - {url}")
